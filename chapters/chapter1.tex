%-*-coding: utf-8-*-

\chapter{Обзор предметной области}

\section{Вспомогательные понятия}

\subsection{Vector representation и Word embedding}
Vector representation (Векторное представление)~--- подход в машинном обучении, при котором некоторой сущности
сопоставляется вектор вещественных чисел.

Формально, $X$~--- множество объектов, тогда фунция $v(x):X \rightarrow R^n$
задает vector representation для объектов из множества $X$.

Причем похожим сущностям сопоставляются близкие
по некоторой метрике вектора, а различным ~--- удаленные друг от друга.

Word embedding ~--- это подход в Natural Language Processing (NLP), который
состоит в отображении слов некоторого словаря в $R^n$ с сохранением
семантических отношений между словами. 
То есть, например, некоторые компоненты вектора могут отвечать за пол объекта,
его одушевленность, съедобность и т.д. Значения компонент не предзадаются, а самоопределяются в результате обучения.


Word embedding обычно предобучают на достаточно большом корпусе текстовых
данных, а затем используют в задачах NLP. Существуют наиболее крупные корпусы слов с соответствующими word embedding, такие как word2vec и glove, которые также будут использоваться в данной работе.

\todo{Визуализация Word Embedding}

\section{Классификация}

Классификация ~-- один из разделов машинного обучения, посвященный решению
задачи классификации.

\subsection{Задача классификации}

Задача классификации~--- имеется множество объектов, каждый из которых принадлежит
к какому-то классу, количество классов чаще всего ограничено.
Существует обучающая выборка~--- множество объектов, метки
класса которых нам известны. Классовая принадлежность остальных объектов
неизвестна. Задача заключается в построении алгоритма, способного
классифицировать (присвоить метку класса) произвольный объект из исходного множества.

Формально, $X$~--- множество объектов, $Y$~--- множество классов,
существует отношение $y* : X \rightarrow Y$, заданное только для обучающей выборки.
Необходимо построить такой алгоритм $a: X \rightarrow Y$, способный для произвольного
$x \in X$ найти $y \in Y$.	

\section{Численная оценка качества классификации}

\subsection{Accuracy}
Accuracy~--- точность классификации. Самый простой способ оценки эффективности классификатора.
$$Accuracy =\frac{P}{N}$$
$P$~--- количество верно классифицированных объектов\\
$N$~--- количество объектов в выборке

\section{Существующие решения}

В данной главе будут приведены существующие решения задачи sentence modelling, для сравнения с предложенным решением.

\todo{Тут какие-то более простые вещи, Paragraph Vector}

\subsection{RNN и LSTM}
Основным инструментом для обработки текстов являются так называемые рекурсивные нейронные сети (Recursive Neural Network).

Рекурсивные нейронные сети предназначены для обработки последовательных данных, таких как звук, текст. В традиционных нейронных сетях все входы считаются независимыми друг от друга, но для многих задач это не является правдой.

Рекурсивные нейронные сети принимают слова последовательности поочереди, сохраняя внутри себя контекст уже принятого текста. Рекурсивными они называются потому что выполняют одну и ту же задачу для каждого элемента последовательности (а конкретно слов в тексте). Они достаточно хорошо отражают процесс восприятия информации человеком: после того как мы прочли начало предложение, в нашей голове уже сформировался некоторый контекст, и следующее слово обрабатывается нами с учетом уже прочитанной информации, а не воспринимается с чистого листа.

\begin{figure}[h]
\includegraphics[scale=0.7]{rnn}
\caption{\textbf{RNN}}
\label{fig:figure1}
\end{figure}

\begin{figure}[h]
\includegraphics[scale=0.7]{rnn-unfold}
\caption{\textbf{RNN в развернутом виде}}
\label{fig:figure2}
\end{figure}

\noindent $U, W, V$~--- параметры RNN сети\\
$x_t$~--- вектор, соответствующий слову $t$ \\
$s_t$~--- информация о первых $t$ словах \\
$o_t$~--- выходной вектор

